<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Particle Filter | Ocxs&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Introduction
Method
Bayes 滤波理论
重要性采样
SIS算法
Resample算法
SIR算法


Result
References">
<meta property="og:type" content="article">
<meta property="og:title" content="Particle Filter">
<meta property="og:url" content="site:ocxsBlog.github.io/2015/12/06/151206-particle-filter/index.html">
<meta property="og:site_name" content="Ocxs's blog">
<meta property="og:description" content="Introduction
Method
Bayes 滤波理论
重要性采样
SIS算法
Resample算法
SIR算法


Result
References">
<meta property="og:updated_time" content="2015-12-14T16:06:27.679Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Particle Filter">
<meta name="twitter:description" content="Introduction
Method
Bayes 滤波理论
重要性采样
SIS算法
Resample算法
SIR算法


Result
References">
  
    <link rel="alternative" href="/atom.xml" title="Ocxs&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/avatar.png" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">ocxs</a></h1>
		</hgroup>

		
		<p class="header-subtitle">To be better</p>
		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Algorithms/" style="font-size: 10px;">Algorithms</a> <a href="/tags/Computer-Vision/" style="font-size: 16.67px;">Computer Vision</a> <a href="/tags/ComputerVision/" style="font-size: 10px;">ComputerVision</a> <a href="/tags/OpenCV/" style="font-size: 16.67px;">OpenCV</a> <a href="/tags/PAT/" style="font-size: 20px;">PAT</a> <a href="/tags/PAT-data-structure/" style="font-size: 20px;">PAT data structure</a> <a href="/tags/Particle-Filter/" style="font-size: 10px;">Particle Filter</a> <a href="/tags/data-structure/" style="font-size: 13.33px;">data structure</a> <a href="/tags/hexo/" style="font-size: 10px;">hexo</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">如果你发现错误，请第一时间联系我！email:ocxswork@163.com</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">ocxs</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img lazy-src="/img/avatar.png" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author">ocxs</h1>
			</hgroup>
			
			<p class="header-subtitle">To be better</p>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
				</div>
			</nav>
		</header>				
	</div>
</nav>
      <div class="body-wrap"><article id="post-151206-particle-filter" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2015/12/06/151206-particle-filter/" class="article-date">
  	<time datetime="2015-12-06T11:14:32.000Z" itemprop="datePublished">2015-12-06</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Particle Filter
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Algorithms/">Algorithms</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Computer-Vision/">Computer Vision</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Particle-Filter/">Particle Filter</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
	  <!-- Table of Contents -->
		
		  <div id="toc" class="toc-article">
			<strong class="toc-title">Table of Contents</strong>
			<ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-number">1.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#估计理论的发展"><span class="toc-number">1.1.</span> <span class="toc-text">估计理论的发展</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#粒子滤波的背景介绍"><span class="toc-number">1.2.</span> <span class="toc-text">粒子滤波的背景介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#名词解释"><span class="toc-number">1.3.</span> <span class="toc-text">名词解释</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#PF的收敛性分析"><span class="toc-number">1.4.</span> <span class="toc-text">PF的收敛性分析</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Method"><span class="toc-number">2.</span> <span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#动态系统的状态空间模型"><span class="toc-number">2.1.</span> <span class="toc-text">动态系统的状态空间模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Bayes_滤波理论"><span class="toc-number">2.2.</span> <span class="toc-text">Bayes 滤波理论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#引言"><span class="toc-number">2.2.1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#递推更新求后验PDF"><span class="toc-number">2.2.2.</span> <span class="toc-text">递推更新求后验PDF</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#重要性采样"><span class="toc-number">2.3.</span> <span class="toc-text">重要性采样</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#蒙特卡罗方法"><span class="toc-number">2.3.1.</span> <span class="toc-text">蒙特卡罗方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#贝叶斯重要性采样"><span class="toc-number">2.3.2.</span> <span class="toc-text">贝叶斯重要性采样</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#序贯重要性采样"><span class="toc-number">2.3.3.</span> <span class="toc-text">序贯重要性采样</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SIS算法"><span class="toc-number">2.4.</span> <span class="toc-text">SIS算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SIR算法"><span class="toc-number">2.5.</span> <span class="toc-text">SIR算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Resample算法"><span class="toc-number">2.6.</span> <span class="toc-text">Resample算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#引言-1"><span class="toc-number">2.6.1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#基本重采样算法"><span class="toc-number">2.6.2.</span> <span class="toc-text">基本重采样算法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#多项式重采样"><span class="toc-number">2.6.2.1.</span> <span class="toc-text">多项式重采样</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Result"><span class="toc-number">3.</span> <span class="toc-text">Result</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#References"><span class="toc-number">4.</span> <span class="toc-text">References</span></a></li></ol>
		  </div>
		
        <blockquote>
<ul>
<li>Introduction</li>
<li>Method<ul>
<li>Bayes 滤波理论</li>
<li>重要性采样</li>
<li>SIS算法</li>
<li>Resample算法</li>
<li>SIR算法</li>
</ul>
</li>
<li>Result</li>
<li>References</li>
</ul>
</blockquote>
<a id="more"></a>
<h1 id="Introduction"><strong>Introduction</strong></h1><h2 id="估计理论的发展"><strong>估计理论的发展</strong></h2><p>　　从1795年高斯(K.Gauss)提出最小二乘估计法开始，估计理论及其方法经历了一个由低级到高级不断发展的过程。最小二乘估计法不考虑观测信号的统计特性，仅保证测量误差的方差最小，一般情况下其估计性能较差。<br>　　1942年Weiner提出了充分利用输入信号和观测信号统计特性的维纳滤波方法，它是一种线性最小方差滤波方法。维纳滤波是一种非递推的频域方法，不便于实时应用。<br>　　1960 年卡尔曼(R.E.Kalman)提出了适用于高斯线性系统状态的递推时域滤波方法即卡尔曼滤波，它是高斯线性系统的最优滤波器。<br>　　1969年 Bucy等人提出了可用于非线性系统的次优滤波器即扩展卡尔曼滤波（EKF），将卡尔曼滤波理论进一步推广到非线性领域。从此 EKF 成为非线性系统估计领域的经典方法。EKF 的基本思想是采用参数化的解析形式<strong>对系统模型的非线性进行线性近似</strong>，基于高斯假设用 Bayes 估计原理进行估计。</p>
<p>以上提出的这些估计方法，都属于Bayes估计，在Bayes估计下，又分最优估计和次优估计。通常的估计准则和方法有：最小二乘估计、极大似然估计、极大验后估计、最小方差估计、线性最小方差估计等</p>
<ul>
<li><strong>最优估计</strong>包括：Kalman滤波，网格(Grid)方法，Bene和Damu滤波；最优估计是指按照某种最优准则来估计未知量的值。</li>
<li><strong>次优估计</strong>：实际问题因为面临大量非线性非高斯问题，最优估计很难找到<a href="http://baike.baidu.com/link?url=vSjhp0H2Fzcp930C9JGHdFB0JkQYL-h4F7emUzZii26AbfQLMe7BuDAz6yJMKezAqrH5i74Di5RE27koJAulwa" target="_blank" rel="external">解析解</a>,所以用次优或逼近算法，可分为四大类：<ul>
<li><strong>解析逼近方法</strong>：包括扩展卡尔曼滤波(Extended Kalman Filter，EKF)，高阶EKF，迭代EKF，其共性如上所说：对非线性进行线性近似。</li>
<li><strong>数值逼近方法</strong>：也称基于网格的逼近方法，它将连续状态空间分解为若干个网格单元，利用离散变量求和来代替积分来逼近状态后验分布，为了获得较好的逼近效果，要求网格必须足够密集，这在状态空间维数较高时导致计算量剧增。隐马尔科夫模型(Hidden Markov Model，HMM)是此种方法的代表，广泛应用于语音处理。</li>
<li><strong>高斯和逼近方法</strong>：针对状态后验分布无法用单个高斯分布有效逼近的问题（例如当后验分布多峰时），高斯和逼近方法采用多个高斯分布的加权和来逼近。该类方法的主要困难在于混合个数的合理选择及混合个数可能随时间呈指数增加。</li>
<li><strong>采样方法</strong>：采样方法使用一组样本来逼近状态后验分布，其典型代表有unscented Kalman滤波（UKF）和<strong>粒子滤波（Particle Filter，PF）</strong>。</li>
</ul>
</li>
</ul>
<hr>
<h2 id="粒子滤波的背景介绍"><strong>粒子滤波的背景介绍</strong></h2><p>　　好了，上面介绍的最后，主角终于登场了，大概也知道为啥会提出粒子滤波了，因为理想很丰满，现实太骨感，哪有那么多线性高斯的问题呢？实际上还是非线性非高斯多啊，先简要介绍PF算法，如下：<br>　　粒子滤波使用了大量随机样本，采用用蒙特卡罗仿真(Monte Carlo Simulation)来完成递推贝叶斯滤波(Recursive Bayesian Filter)过程，其核心是使用一组具有相应权值的随机样本（粒子）来表示<strong>状态的后验分布</strong>。该方法的基本思路是选取一个<strong>重要性概率密度</strong>并从中进行随机抽样，得到一些带有相应<strong>权值</strong>的随机样本后，在状态观测的基础上调节权值的大小和粒子的位置，再使用这些样本来逼近状态后验分布，最后通过这组样本的加权求和作为状态的估计值。粒子滤波不受系统模型的线性和高斯假设约束，采用样本形式而不是函数形式对状态概率密度进行描述，使其不需要对状态变量的概率分布作过多的约束，适用于任意非线性非高斯动态系统，是目前最适合于非线性、非高斯系统状态的滤波方法。</p>
<p>　　在上世纪50年代，有了序贯重要性采样(Sequential Importance Sampling，SIS)算法，一种通过离散随机样本逼近概率分布的蒙特卡罗方法（Monte Carlo）。后来针对SIS算法中的粒子<strong>退化</strong>(degeneracy)问题，1993年Gardon等人重采样(resampling)，得到新的算法–序列重要性重采样算法（Sequential Importance Resampling，SIR）。但是还没完，SIR算法又出现粒子多样性匮乏问题，针对退化和多样性匮乏这两个问题，又提出下面两个解决办法：</p>
<ul>
<li><strong>优化重采样，减小粒子多样性匮乏</strong>：目前最常用最简单的四种重采样算法：(1)多项式重采样算法,(2)残差重采样算法,(3)分层重采样算法,(4)系统重采样算法，这四种方法以速度和结果综合考量，系统重采样最优。当然又更好的算法：Gibbs采样器和Metropolis-Hasting方法等<strong>马尔可夫链蒙特卡洛(MCMC)方法</strong>解决粒子退化问题。针对重采样，科学家们搞出来了遗传粒子滤波器，正则化粒子滤波（regularized particle filter，RPF）算法，辅助粒子滤波（auxiliary particle filter,APF）算法。</li>
<li><strong>产生既接近系统状态真实概率密度又便于从中抽样的重要性概率密度</strong>：如UPF(Unscented Particle Filter),高斯粒子滤波（Gaussian particle filter,GPF）算法,高斯混合粒子滤波（Gaussian sum particle filter,GSP）算法.</li>
</ul>
<hr>
<h2 id="名词解释"><strong>名词解释</strong></h2><ul>
<li>1.粒子<strong>退化(degeneracy)</strong>问题: 样本（又称为粒子）退化是指经过若干次迭代后，大部分粒子的权值极小以至于可以忽略不计，粒子权值的方差随时间逐渐增大，大量运算时间浪费在这些对系统状态估计几乎不起作用的粒子权值更新上。</li>
<li>2.粒子<strong>多样性匮乏</strong>问题：SIR算法的重采样在一定程度上缓解了粒子退化问题，但是它的重采样在原有粒子集合组成的离散分布上依粒子权值大小，采取随机选取复制的方式进行，即采用以较大概率复制权值较高粒子的方法。这样就使原有粒子集合中有很多粒子由于权值太小没有“后代”，而少数权值较大的粒子则有很多相同的“后代”，导致重采样得到的粒子集合由大量重复粒子构成，使粒子集合失去了多样性，从而限制了粒子并行运行的机会。这一现象又称为粒子多样性匮乏问题。</li>
<li>3.<strong>重要性密度函数</strong>：</li>
</ul>
<hr>
<h2 id="PF的收敛性分析"><strong>PF的收敛性分析</strong></h2><p>　　在粒子滤波算法收敛性分析上，标准粒子滤波满足中心极限定理。标准粒子滤波产生的状态近似分布几乎肯定收敛（弱收敛）于状态后验分布。为了找到一个合适的后验概率密度函数，我们就可以通过采样(多用蒙特卡罗方法采样)来去近似这个概率密度函数(Probability Density Function,PDF)(不知道近似这个词用的准不准确)，因为他满足中心极限定理，所以我们才可以用采样的方法，样本数量越多，自然越好。</p>
<p>　　上面简单的介绍了一下PF的背景，下面开始进入正题，我也是最近因为课设接触了粒子滤波，大部分理论是直接copy别人的论文上面的，参考文献附在文章最后，我觉得对于一个不了解刚入门的东西，看CNKI的文献比直接阅读英文文献要好一点(尤其是那些博士论文的背景介绍部分，讲的很详细的，可以当科普文章看)，毕竟前辈们用更加严谨的说法用我的母语来讲述PF的理论，比我自己说的要好的多，也更能轻松的让我理解，copy过来也是为自己以后复习方便，中间加入自己的一些理解，<strong>如果有大神看到错误，恳请指出~</strong></p>
<hr>
<h1 id="Method"><strong>Method</strong></h1><p>估计问题一般分为三类：</p>
<ul>
<li>(1)从当前和过去的观测值来估计信号的当前值，称为滤波；</li>
<li>(2)从过去的观测值来估计信号的现在值或将来值，称为预测或外推；</li>
<li>(3)从过去的观测值来估计过去的信号值，称为平滑或内插。</li>
</ul>
<h2 id="动态系统的状态空间模型"><strong>动态系统的状态空间模型</strong></h2><p>　　<strong>动态系统</strong>是指输出信号不仅取决于同时刻的激励信号，而且与它过去的工作状态有关的系统。<br>　　<strong>状态空间模型</strong>是描述动态系统的完整模型，它用系统方程来描述状态随时间演变的过程，并用观测方程来描述与状态有关的噪声变量，表达了由于输入引起系统内部状态的变化并由此使输出发生的变化。</p>
<p>　　状态空间模型包括：（1）<strong>系统模型</strong>，用于描述系统状态随时间演变的过程；（2）<strong>观测模型</strong>，用于将系统在某时刻的输出和系统的状态联系起来。</p>

\begin{equation}
x_k = f(x_{k-1}, {\mu}_{k-1}) \tag{1}
\end{equation} 

<p>\begin{equation}<br>y_k = h(x_k, v_k) \tag{2}<br>\end{equation} </p>
<p>其中，$f(.)$和$h(.)$为已知函数，系统噪声$x_k$和观测噪声$v_k$是概率密度已知的随机变量，$x_k$代表系统在$k$时刻的状态变量，$y_k$代表$x_k$的观测值，$u_k$和$v_k$相互独立且独立于系统状态.</p>
<p>　　这里(1)就是系统方程，(2)就是观测方程，在实际问题中，$y_k$可能就是一组由传感器得到的数据，意思就是说$y_k$不一定是由观测方程算出来的，而是直接得到的，比如室内的温度，可以直接由温度计得到，这就是观测数据，系统方程提供的是预测值，我们可以根据观测值来修正预测值，在MATLAB官网上file exchange中提供的<a href="http://www.mathworks.com/matlabcentral/fileexchange/35468-particle-filter-tutorial" target="_blank" rel="external">particle filter tutorial</a>中，则是利用观测方程来生成观测数据，因为这是仿真，所以用观测方程来模拟生成，而不是用传感器直接得到。</p>
<p>上述状态空间模型的统计描述方式如下：</p>
<ul>
<li>(1)对应于系统模型有系统的状态转移概率密度
\begin{equation}
p(x_k|x_{k-1})
\end{equation} 
</li>
<li>(2)对应于观测模型有系统状态的观测似然概率密度
\begin{equation}
p(y_k|x_k)
\end{equation} 

</li>
</ul>
<p>并假设：系统状态$x_k$服从一阶马尔可夫过程，系统观测$y_k$独立，已知系统状态的初始先验密度(Prior Density)为$p(x_0)$.</p>

P.S. 一阶markov过程在这里的意思就是说系统状态$x_k$只和$x_{k-1}$有关，和$k-1$之前的状态(例如$x_{k-2}$)通通无关。同理如果$x_k$和$x_{k-1}$，$x_{k-2}$有关，和$k-2$之前的状态(例如$x_{k-3}$)通通无关就叫二阶markov过程。依次类推。

<h2 id="Bayes_滤波理论"><strong>Bayes 滤波理论</strong></h2><h3 id="引言"><strong>引言</strong></h3><p>　　贝叶斯估计理论及其方法为动态系统的估计问题提供了一类严谨的解决框架，它利用已知的信息建立系统状态的概率密度估计，可以得到对系统状态估计的最优解。贝叶斯估计利用系统方程预测状态的先验概率密度，再利用最新的观测值进行修正，得到状态的后验概率密度，包括了观测值和先验知识在内的所有可利用的信息。<br>　　卡尔曼滤波、扩展卡尔曼滤波和粒子滤波都是基于状态空间模型的贝叶斯估计具体实现算法。<br>　　卡尔曼滤波要求系统线性和噪声服从高斯分布；扩展卡尔曼滤波同样要求噪声服从高斯分布。而粒子滤波不用满足系统为线性、噪声高斯分布的限制条件。粒子滤波是蒙特卡罗方法和贝叶斯估计理论结合的产物，它通过非参数化的蒙特卡罗模拟方法从时域实现递推贝叶斯估计。</p>
<p>　　<strong>贝叶斯估计的主要目的是利用先验知识和实际观测数据来构造未知系统状态的概率密度函数</strong>。	设$k$代表时间，$x_{0:k}$代表未知变量列即$x_{0:k}=\{{x_i:i=0,...,k}\}$,$y_{1:k}$代表观测变量列即$y_{1:k}=\{y_i:i=1,...,k\}$,若给定观测量$y_{1:k}$，则未知量$x_{0:k}$的条件概率分布为:
\begin{equation}
p(x_{0:k}|y_{1:k}) = \frac{p(x_{0:k})p(y_{1:k}|x_{0:k})}{\int p(y_{1:k}|x_{0:k})p(x_{0:k})dx_{0:k}} \tag{3}
\end{equation}

其中，$p(x_{0:k})$称为先验概率密度，$p(y_{1:k}|x_{0:k})$称为观测量为$y_{1:k}$时的似然概率密度，$p(x_{0:k}|y_{1:k})$称为后验概率密度，这就是贝叶斯定理。
</p>

　　从上式可见，通过似然概率密度观测数据修正了先验信息。贝叶斯定理描述了从先验知识（先验概率密度）开始，不断利用陆续到来的新观测数据修正先验知识，从而得到修正后的未知量知识（后验概率密度）的过程。先验概率密度归纳了新观测数据到达之前未知状态变量的所有信息。似然概率密度表达了在实际观测数据已知的前提下未知状态变量出现的概率，是实际观测数据和未知变量之间的逻辑联系。由于得到新观测数据的修正，后验概率密度较之先验概率密度更加接近被估计量的真实概率密度。而这个后验概率密度又是下一个新观测量到来时被估计量的先验概率密度。
上述后验概率密度$p(x_{0:k}|y_{1:k})$是贝叶斯估计问题的完整解。　　而滤波问题就是要计算后验滤波概率密度$p(x_k|y_{1:k})$,它是$p(x_{0:k}|y_{1:k})$的边沿密度即
\begin{equation}
p(x_{0:k}|y_{1:k}) = \int \int .. \int p(x_{0:k}|y_{1:k})dx_0dx_1...d_{x-1} \tag{4}
\end{equation} 


　　对于动态系统，从该后验滤波概率密度就可以计算系统状态的各种估计，如以均值作为系统状态的估值等.由(3)和(4)式可见，当每一个新观测数据到来时，后验滤波概率密度$p(x_k|y_{1:k})$就要被重新计算一次，这是十分不方便的。为此，采用如下递推更新方法来获得该后验滤波概率密度:

<ul>
<li>(1)<strong>预测</strong>—从$k-1$时刻所得到的后验滤波概率密度$p(x_{k-1}|y_{1:k-1})$出发，利用系统模型来预测$k$时刻$x_k$的概率密度，得到$k$时刻$x_k$的先验滤波概率密度$p(x_k|y_{1:k-1})$;</li>
<li>(2)<strong>更新</strong>—当$k$时刻的观测值$y_k$到来时，利用它修正上述先验滤波概率密度，从而得到$k$时刻的后验滤波概率密度$p(x_k|y_{1:k})$。</li>
</ul>
<p>　　设$k-1$时刻滤波概率密度$p(x_{k-1}|y_{1:k-1})$已知，假设系统状态$x_k$服从一阶马尔可夫过程且系统观测$y_k$独立。</p>
<hr>
<h3 id="递推更新求后验PDF"><strong>递推更新求后验PDF</strong></h3><p>　　首先，通过预测步骤得到不包含$k$时刻观测值的$k$时刻系统状态先验滤波概率密度$p(x_k|y_{1:k-1})$如下:
\begin{equation}
p(x_k|y_{1:k-1}) = \int p(x_k|x_{k-1}) p(x_{k-1}|y_{1:k-1}) dx_{k-1} \tag{5}
\end{equation}

其中，$p(x_k|x_{k-1})$是系统状态的转移概率密度。
<br>文献[2]中指出式(5)即<a href="https://en.wikipedia.org/wiki/Chapman%E2%80%93Kolmogorov_equation" target="_blank" rel="external">Chapman–Kolmogorov equation</a>,然而我并没有看懂wiki里的解释。下面解释一下式(5)是怎么得到的：</p>
<ul>
<li>(1)首先我们知道$x_k$服从一阶markov过程，所以$p(x_k|x_{k-1}, y_{1:k-1}) = p(x_k|x_{k-1})$ ;</li>
<li>(2)把上式带入式(5)中，利用Bayes公式替换即可，具体如下：
\begin{equation}
p(x_k|y_{1:k-1}) = \int p(x_k|x_{k-1}) p(x_{k-1}|y_{1:k-1}) dx_{k-1} 
\quad=\int p(x_k|x_{k-1}, y_{1:k-1}) p(x_{k-1}|y_{1:k-1}) dx_{k-1} \\
\quad=\int \frac{p(x_k,x_{k-1}, y_{1:k-1})}{p(x_{k-1}, y_{1:k-1})}\frac{p(x_{k-1},y_{1:k-1})}{p(y_{1:k-1})}dx_{k-1} 
\quad=\int \frac{p(x_k,x_{k-1}, y_{1:k-1})}{p(y_{1:k-1})}  dx_{k-1} 
\quad=\int p(x_k,x_{k-1})| p(y_{1:k-1})  dx_{k-1}	\tag{6}
\end{equation} 

</li>
</ul>
<p>然后，利用$k$时刻的观测值$y_k$，通过更新步骤修正$p(x_k|y_{1:k-1})$，得到$k$时刻系统状态后验滤波概率密度$p(x_k|y_{1:k})$，其推导过程如下：<br>由贝叶斯公式有,<br>
$$p(x_k|y_{1:k}) = \frac{p(x_k)p(y_{1:k}|x_k)}{p(y_{1:k})} = \frac{p(x_k)p(y_k, y_{1:k-1}|x_k)}{p(y_k, y_{1:k-1})} \tag{7}$$
<br>由条件概率定义有:<br>
$$p(y_k, y_{1:k-1}) = p(y_{1:k-1}) p(y_k | y_{1:k-1})  \tag{8}$$
<br>由联合分布概率公式有:<br>
$$p(y_k, y_{1:k-1}|x_k) = \frac{p(y_k, y_{1:k-1}, x_k)}{p(x_k)} 
= \frac{p(y_k, y_{1:k-1}, x_k)}{p(y_{1:k-1}, x_k)} \frac{p(y_{1:k-1}, x_k)}{p(x_k)} = p(y_k|y_{1:k-1}, x_k)p(y_{1:k-1}|x_k) \tag{9}$$
<br>又由贝叶斯公式有:<br>
$$p(y_{1:k-1}|x_k) = \frac{p(y_{1:k-1})p(x_k|y_{1:k-1})}{p(x_k)} \tag{10}$$
<br>将式(8)(9)(10)代入式(7)得:<br>
$$p(x_k|y_{1:k}) = \frac{p(y_k| y_{1:k-1}, x_k) p(x_k|y_{1:k-1}) p(y_{1:k-1}) p(x_k)}{p(x_k) p(y_{1:k-1}) p(y_k|y_{1:k-1})} \tag{11}$$
<br>根据假设各个系统观测$y_k$相互独立，即有:<br>
$$p(y_k|y_{1:k-1}, x_k) = p(y_k|x_k) \tag{12}$$
<br>将(12)式代入(11)式并消去分子和分母的共同项,得后验滤波概率密度 $p(x_k|y_{1:k})$如下:<br>
$$p(x_k|y_{1:k}) = \frac{p(y_k|x_k) p(x_k|y_{1:k-1})}{p(y_k|y_{1:k-1})} \tag{13}$$
<br>其中，$p(y_k|x_k)$是似然概率密度，它与观测方程和观测噪声$v_k$的统计特性有关：<br>
$$p(y_k|x_k) = \int \delta (y_k - h(x_k, v_k))p(v_k) dv_k \tag{14}$$
<br>这里，$\delta(.)$是Dirac delta函数，$p(v_k)$是$v_k$的概率密度。<strong>然而我并不知道式(14)是怎么得来的，是什么道理</strong>。而<br>
$$p(y_k|y_{1:k-1}) = \int p(v_k|x_k) p(x_k|y_{1:k-1}) dx_k \tag{15}$$
<br>它一般是一个归一化常数。</p>
<p>　　这样由(5)式和(13)式就构成了后验滤波概率密度的递推公式，实现了由$k-1$时刻后验滤波概率密度$p(x_{k-1}|y_{1:k-1})$到$k$时刻后验滤波概率密度$p(x_k|y_{1:k})$的递推更新过程，从理论上提供了求后验滤波概率密度的方法。</p>
<p>　　但实际问题中只有很少类型的系统可以直接利用上述解析方法求得后验滤波概率密度。例如，针对线性高斯系统的卡尔曼滤波器。对于大多数动态系统，由于各种原因（例如，在很多实际问题中上述(5)式的积分是很难实现的），直接利用上述方法很难求得后验滤波概率密度的解析解，该方法在实际操作中受到较大的限制。下面的贝叶斯重要性采样和序贯重要性采样给出了这个问题的解决方法。</p>
<hr>
<h2 id="重要性采样"><strong>重要性采样</strong></h2><h3 id="蒙特卡罗方法"><strong>蒙特卡罗方法</strong></h3><p>　　蒙特卡罗(Monte Carlo, MC)方法,又称随机抽样或统计模拟方法，蒙特卡罗算法并不是一种算法的名称，而是对一类随机算法的特性的概括。此外，还有一种随机算法叫拉斯维加斯算法(Las Vegas algorithm)。</p>
<ul>
<li><strong>蒙特卡罗算法</strong>：采样越多，越<strong>近似</strong>最优解；</li>
<li><strong>拉斯维加斯算法</strong>：采样越多，越<strong>有机会</strong>找到最优解。</li>
</ul>
<p>　　怎么理解上面这两句话，可以参考<a href="http://www.zhihu.com/question/20254139/answer/33572009" target="_blank" rel="external">这里</a>,讲的深入浅出，简单易懂。按照<a href="https://en.wikipedia.org/wiki/Monte_Carlo_method" target="_blank" rel="external">wikipedia里的解释</a>,MC Method 万变不离其宗，可以概括为以下内容(为了保证理解，我就不用我三脚猫的功夫来翻译了)：</p>
<ul>
<li>(1) Define a domain of possible inputs；</li>
<li>(2) Generate inputs randomly from a probability distribution over the domain;</li>
<li>(3) Perform a deterministic computation on the inputs;</li>
<li>(4) Aggregate the results.</li>
</ul>
<p>举个例子：我们知道圆和它的的外接正方形的面积比是$\pi/4$,然后我们根据MC Method来估计$\pi$的取值，如下：</p>
<ul>
<li>(1) 首先画个圆，然后在其基础上画出它的外接正方形；</li>
<li>(2) 然后我们往里面撒米啊或者沙子之类的东西，注意不能随便撒，得保持均匀的撒，英文用的词叫uniform；</li>
<li>(3) 然后统计圆里面的米粒个数和整个正方形里的个数；</li>
<li>(4) 最后我们计算出米粒的比值，这个比值我们就可以认为接近$\pi/4$，然后在乘以4，就能得到$\pi$的估值。</li>
</ul>
<p>　　在上面这个例子中，正方形就是我们之前提到的domain of possible inputs，我们撒米粒就相当于Generate random inputs，注意我们需要按照a probability distribution来撒。最后我们得到统计来得到近似值。</p>
<p>有两点需要注意：</p>
<ul>
<li>(1)如果米粒不是uniformly distributed，那么我们最后得到的approximation，即$\pi$的估计值就会很离谱，或者说不接近真实值，英文说是poor，我不知道如何翻译比较恰当。</li>
<li>(2)我们必须有大量的input，即我们要撒很多米粒，样本足够多式，我们才能认为结果不是poor的，可以参考大数定理。这样侧面印证上面说的，采样越多，越近似最优解。</li>
</ul>
<h3 id="贝叶斯重要性采样"><strong>贝叶斯重要性采样</strong></h3><p>　　通常，求解后验概率密度并不是我们的最终目的，我们希望通过这个后验概率密度得到服从这个概率密度分布的某随机变量的某函数的估计值，如期望值或方差等，而这个<strong>后验概率密度只是一个用来计算这些值的工具</strong>.例如，设 $g(x_{0:k})$为状态变量$x_{0:k}$的任意函数，则$g(x_{0:k})$ 的数学期望为：<br>
$$E(g(x_{0:k})) = \int g(x_{0:k}) p(x_{0:k} | y_{1:k}) dx_{0:k} \tag{16}$$
</p>
<p>　　根据蒙特卡罗仿真原理,可以从后验概率密度 $p(x_{0:k} | y_{1:k})$ 中抽取$N$个个独立同分布(i.i.d.)的样本$\{x_{0:k}(i), i=1,2,…,N\}$，使 <br>
$$E(g(x_{0:k})) \approx \frac{1}{N} \sum_{i=1}^{N} g(x_{0:k}(i)) \tag{17}$$
</p>
<p>当$N$足够大时，该近似值绝对收敛于 $E(g(x_{0:k}))$ .</p>
<p>　　实际问题中，通常较难甚至无法直接从后验概率密度 $p(x_{0:k} | y_{1:k})$中抽样。于是，引入一个被称为重要性概率密度的参考分布$q(x_{0:k} | y_{1:k})$ ,该参考分布应已知且便于从中抽样。利用该重要性概率密度和贝叶斯公式有:</p>

$$E(g(x_{0:k})) = \int g(x_{0:k}) \frac{p(x_{0:k}|y_{1:k})}{q(x_{0:k} | y_{1:k})} q(x_{0:k} | y_{1:k}) dx_{0:k} 
= \int g(x_{0:k}) \frac{p(y_{1:k}| x_{0:k}) p(x_{0:k})}{p(y_{1:k}) q(x_{0:k} | y_{1:k})} q(x_{0:k} | y_{1:k}) dx_{0:k} \\
= \int g(x_{0:k}) \frac{{w_k}^{*}(x_{0:k})}{p(y_{1:k})} q(x_{0:k} | y_{1:k}) dx_{0:k} \tag{18}$$

上式令权值 ${w_k}^{*}(x_{0:k})$ 为

$${w_k}^{*}(x_{0:k}) = \frac{p(y_{1:k} | x_{0:k}) p(x_{0:k})}{q(x_{0:k} | y_{1:k})} \tag{19} $$

因为(18)式是对$x_{0:k}$积分，故$y_{1:k}$可看作常数处理，从而
$$ E(g(x_{0:k})) = \frac{\int g(x_{0:k}) {w_k}^{*}(x_{0:k}) q(x_{0:k}|y_{1:k})}{p(y_{1:k})} \tag{20}$$

又因为
$$ p(y_{1:k}) = \int p(y_{1:k}, x_{0:k}) dx_{0:k} 
= \int \frac{p(y_{1:k}|x_{0:k}) p(x_{0:k}) q(x_{0:k}|y_{1:k})}{q(x_{0:k}|y_{1:k})} dx_{0:k} 
= \int {w_k}^{*}(x_{0:k}) q(x_{0:k}|y_{1:k}) dx_{0:k} \tag{21} $$

将(21)代入(20)得：
$$ E(g(x_{0:k})) = \frac {\int g(x_{0:k}) {w_k}^{*}(x_{0:k}) q(x_{0:k}|y_{1:k}) dx_{0:k}} {\int {w_k}^{*}(x_{0:k})  q(x_{0:k}|y_{1:k}) dx_{0:k}}  \tag{22} $$

<p>依据蒙特卡罗仿真原理，从重要性概率密度 $q(x_{0:k}|y_{1:k})$中抽取$N$个独立同分布的样本$\{x_{0:k}(i), i=1,2,…,N \}$ ,则上述数学期望可近似表示为：</p>

$$E(g(x_{0:k})) \approx \frac{\frac{1}{N} \sum_{i=1}^{N} g(x_{0:k}(i)) {w_k}^{*}(x_{0:k}(i)) }{\frac{1}{N} \sum_{i=1}^{N} {w_k}^{*}(x_{0:k}(i)) } 
= \sum_{i=1}^{N} g(x_{0:k}(i)) {w_k}(x_{0:k}(i)) \tag{23}$$

<p>其中，<br>
$$ w_k(x_{0:k}(i)) = \frac{ {w_k}^{*}(x_{0:k}(i))}{ \sum_{i=1}^{N} {w_k}^{*}(x_{0:k}(i))} \tag{24}$$
</p>
<p>称为归一化权值。<br>　　<strong>贝叶斯重要性采样的核心思想</strong>是利用一系列随机样本及其权值来近似表示所需的后验概率密度，进而得到所需统计量的估计值。一个随机变量的后验概率密度可以用一系列离散样本及其权值来近似表示，近似的程度高低依赖于样本的数量$N$。通常，随机变量的后验概率密度无法直接得到的，而贝叶斯重要性采样提供了一种解决该问题的方法。</p>
<hr>
<h3 id="序贯重要性采样"><strong>序贯重要性采样</strong></h3><p>　　由上述分析可见，贝叶斯重要性采样方法存在如下缺陷：每当新的观测数据 $y_k$到来时都需要重新从重要性概率密度 $q(x_{0:k} | y_{1:k})$中抽取样本$\{x_{0:k}(i),i=1,...,N\}$,并且需要按照式(19)重新计算每个$x_{0:k}(i)$ 的权值$w_k(x_{0:k}(i))$ ，这就会占用很大的存储空间以及增大了计算量，不便于实际应用。序贯重要性采样（Sequential Importance Sampling,SIS）将贝叶斯重要性采样方法写成序列形式，其权值采用递归更新方式计算，使概率密度估计以递推方式实现。<br>　　为了递推估计概率密度，重要性概率密度  $q(x_{0:k} | y_{1:k})$ 可分解为(前面讲过，联合概率分布公式)：

$$ q(x_{0:k} | y_{1:k}) = q(x_k|x_{0:k-1}, y_{1:k}) q(x_{0:k-1} | y_{1:k-1}) \tag{25}$$
<br>即随着观测数据的不断到来，新样本 $x_{0:k-1}(i) \sim q(x_{0:k}|y_{1:k})$可以通过将新数据$x_k(i) \sim q(x_k|x_{0:k-1}(i), y_{1:k})$添加进旧样本$x_{0:k-1}(i) \sim q(x_{0:k-1} | y_{1:k-1})$ 中得到。<br>将(25)式代入(19)式得：<br>
$$ {w_k}^{*}(x_{0:k}) = \frac{p(y_{1:k} | x_{0:k}) p(x_{0:k})}{q(x_k | x_{0:k-1}, y_{1:k}) q(x_{0:k-1} | y_{1:k-1}) } \tag{26} $$
<br>又由(19)式还可得：<br>
$$ {w_{k-1}}^{*}(x_{0:k-1}) = \frac{p(y_{1:k} | x_{0:k}) p(x_{0:k})}{ q(x_{0:k-1} | y_{1:k-1}) } \tag{27} $$
<br>这样由(26)(27)式可得:<br>
$$ {w_{k}}^{*}(x_{0:k}) = {w_{k-1}}^{*}(x_{0:k-1}) \frac{p(y_k | x_k) p(x_k | x_{k-1})}{ q(x_k | x_{0:k-1}, y_k) } \tag{27} $$
</p>
<hr>
<h2 id="SIS算法"><strong>SIS算法</strong></h2><p>SIS算法实现的步骤如下：</p>
<ul>
<li>(1)预测: $x_k(i) \sim q(x_k|x_{0:k-1}(i), y_{1:k}) (i = 1,2,...,N) $ 得到新样本 $x_{0:k}(i) = \{x_k(i), x_{0:k-1}(i)\}$ ;</li>
<li>(2)更新: 利用式(28)计算各新样本的权值  ${w_k}^{*}(x_{0:k}(i))$ 如下：
$$ {w_k}^{*}(x_{0:k}(i)) = {w_{k-1}}^{*}(x_{0:k-1}(i)) \frac{p(y_k|x_k(i)) p(x_k(i) | x_{k-1}(i))}{ q(x_k(i) | x_{0:k-1}(i), y_{1:k})} \tag{28} $$

归一化上述权值如下:
$$ w_k(x_{0:k}(i)) = \frac{ {w_k}^{*}(x_{0:k}(i))}{ q(x_k(i) | x_{0:k-1}(i), y_{1:k}) } \tag{29} $$

从而得到一组加权样本$\{ (x_{0:k}(i), w_k(x_{0:k}(i))), i=1,2,...,N\}$  ,则所求概率密度可用这组样本的加权和近似表示为:<br>
$$p(x_{0:k} | y_{1:k}) \approx \sum_{i=1}^{N} w_k(x_{0:k})\delta(x_{0:k} - x_{0:k}(i)) \tag{30}$$

下文中我们一律将$ {w_k}^{*}(x_{0:k}(i))$ 简写为 ${w_k}^{*}(i)$, 将$ w_k(x_{0:k}(i))$简写为$w_k(i)$  。<br>结合(4)式和(31)式可知，$x_k$的滤波概率密度可近似表示为<br>
$$p(x_k|y_{1:k}) \approx \sum_{i=1}^{N} w_k(i)\delta(x_k-x_k(i)) \tag{31}$$

$x_k$的最小均方误差估计值(minimum mean squareerror estimation, MMSE)为：
$$ \hat{x_k} = \sum_{i=1}^{N} w_k(i) x_k(i) \tag{32}$$

序贯重要性采样的样本权值采用便于计算的递归更新方式，并且其强大数定理和中心极限定理成立。序贯重要性采样算法是递推的贝叶斯重要性采样算法，是粒子滤波的基础。到目前为止，各种不同的粒子滤波算法都是基于序贯重要性采样算法的。</li>
</ul>
<hr>
<h2 id="SIR算法"><strong>SIR算法</strong></h2><p>　　序贯重要性采样算法中存在的基本问题是样本退化问题。它指算法经过若干次迭代后，样本权值的方差会随时间逐渐增大，使得少数样本的权值很大，而大多数样本的权值很小，以至于可以忽略不计。这意味着大量计算工作都浪费在对求解滤波概率密度几乎不起任何作用的样本的权值更新上。消除样本退化的主要手段有两种：<strong>选取适当的重要性概率密度和样本重采样</strong>。一种简便易行且使用较为广泛的方法就是选择具有先验性质的系统状态转移概率密度作为重要性概率密度，即<br>
$$ q(x_k | x_{0:k-1}(i), y_{1:k}) = p(x_k|x_{k-1}(i)) \tag{33}$$
<br>将式(33)代入式(29)得：<br>
$$ {w_k}^{*}(i) = {w_{k-1}}^{*} p(y_k|x_k(i)) \tag{34}$$
<br>　　但该方法的缺点是没有利用最新观测信息$y_k$.从状态转移概率密度中采样所得样本的权值方差较大，未能克服样本权值的退化问题。但由于其形式更简单且易于实现，在各种粒子滤波算法中己经被广泛使用。<br>　　减小退化的另一种方法是采用重采样技术。重采样的基本思想是对(31)式或(32)式中后验概率密度的离散近似表示再进行一次采样，繁殖权值较高的样本而淘汰权值较低的样本，重新生成一个新样本集合，以克服样本权值退化问题。由于新样本独立同分布，因此重采样所得新样本的权值均为$1/N$.<br>　　1993 年 Gordon 等为了克服 SIS 算法中的样本退化问题，首次将重采样(resampling)步骤引入 SIS 算法，并由此产生了基本粒子滤波算法—序列重要性重采样算法（sequential importance resampling，SIR）。在粒子滤波中样本又被称为粒子，样本退化又称为粒子退化。<strong>SIR 算法选择先验的系统状态转移概率密度作为重要性概率密度</strong>，在 SIS 算法的基础上增加了重采样步骤，由<strong>预测、更新和重采样</strong>三部分组成。SIR 算法中的重采样采用的是多项式重采样算法，其过程如下：<br>　　每次从$[0,1]$上的均匀分布中随机抽取一个样本$\mu \sim U[0,1]$, 满足下式的粒子$x_k(i)$被选出并复制到新的粒子集合中<br>
$$ \sum_{j=1}^{i-1}w_k(j) \le \mu \le \sum_{j=1}^{i}w_k(j) \tag{35}$$
<br>　　该过程重复$N$次，得到$N$个新粒子，组成一个新粒子集合，每个新粒子的权值均为 $1/N$。上述过程等价于从参数为$(N, w_k(i))$的多项式分布中抽样。此后，Liu、Kitagawa 和 Doucet 等人又在多项式重采样算法的基础上分别提出了残差重采样(Residual Resampling) 算法、分层重采样(Stratified Resampling)算法和系统重采样(Systematic Resampling)算法。从滤波精度和计算量方面综合考虑，上述四种重采样算法中以系统重采样算法较优。</p>
<p>SIR 算法的步骤如下：</p>
<ul>
<li>(1)预测:从系统状态转移概率密度中抽取新粒子:   $x_k(i) \sim p(x_k|x_{k-1}(i)) (i=1,2,...,N)$  </li>
<li>(2)更新:利用式(34)计算各新样本的权值  ${w_k}^{*}(i)$ 并归一化如下：
$$ w_k(i) = \frac{ {w_k}^{*}}{ \sum_{i=1}^{N} {w_k}^{*}(i)} \tag{36}$$
</li>
<li>(3)状态估计:
$$ \hat{x_k} = \sum_{i=1}^{N} {w_k}(i)x_k(i) \tag{37}$$
</li>
<li>(4)进行多项式重采样。</li>
</ul>
<hr>
<h2 id="Resample算法"><strong>Resample算法</strong></h2><h3 id="引言-1"><strong>引言</strong></h3><p>　　重采样是解决粒子退化问题的一种重要技术手段，自粒子滤波出现以来众多国内外学者一直致力于重采样技术的研究。1993年Gordon等人为了克服粒子退化问题，将多项式重采样(Multinomial Resampling)算法应用在他们提出的SIR粒子滤波算法中。多项式重采样在一定程度上缓解了粒子退化问题，但是它的计算量较大。1993年Liu等人在多项式重采样方法的基础上提出了残差重采样(Residual Resampling) 算法，其计算量大大小于多项式重采样算法。1996年Kitagawa等人对多项式重采样算法进行了改进，进而提出了分层重采样(Stratified Resampling)算法。<br>　　同年M.Pitt和N.Shephard在他们提出的辅助粒子滤波（APF）算法中，利用下一个时刻系统状态的观测值来指导上一个时刻的粒子重采样。由于该重采样方法考虑了系统状态的最新观测值，其在系统噪声较小时获得了较好的估计性能改进。<br>
　　2000年Doucet等人在分层重采样算法的基础上提出了系统重采样(Systematic Resampling)算法。上述重采样算法均采用在离散分布 $\{ {x_k(i), w_k(i)}_{i=1}^{N}\}$  上以较大概率复制权值较高粒子的方法进行重采样，其缺陷是存在粒子多样性匮乏问题。  
<br>　　针对粒子多样性匮乏问题，2001年Musso等提出正则化（regularized）重采样算法。该算法在一个连续分布上进行重采样，改善了重采样带来的粒子多样性匮乏问题，在系统噪声较小时改善了估计性能。但该算法有一个理论上的缺陷，即重采样后所得的粒子群不能保证渐进地接近所求分布。此外，还出现了一类在重采样过程中增加马尔可夫蒙特卡罗(Markov Chain Monte Carlo, MCMC)移动步骤的重采样算法。<br>
　　粒子退化的程度可以采用有效样本数（effective sample size） $N_{eff}$  来衡量，其定义如下:
$$ n_{eff} = \frac{N}{1+Var({w_k}^{'}(i))} \tag{38}$$

其中，$N$为实际使用的粒子数，$Var(.)$代表方差函数，${w_k}^{'}$被称为“真实权值”,其定义如下：

$${w_k}^{'}(i) = \frac{p(x_k(i) | y_{1:k})}{q(x_k(i) | x_{k-1}(i), y_k)} \tag{39}$$
</p>
<p>由(38)式可见，等号右端分式的分子部分实际上就是粒子滤波最终所要逼近的后验概率密度函数，因此上述有效样本数在计算上存在较大困难。实际应用中通常采用下式来得到  $N_{eff}$ 的估计值 $\hat{N_{eff}}$  :<br>
$$ \hat{ N_{eff}} = \frac{1}{ \sum_{i=1}^{N} {(w_k(i))}^2} \tag{40}$$
<br>其中，$w_k(i)$是由(29)式计算得到并归一化后的权值。<br>　　有效样本数的值越小表示粒子退化程度越严重。由(38)式可见，增大实际使用的粒子数量可以减小粒子退化程度，但过大的粒子数量会带来计算量增大的问题，尤其当被估计变量的维数较高时。<br>　　对于何时进行重采样，一种观点是每次迭代都进行重采样；另一种观点是不必每次都重采样，只是当有效样本数小于某个阈值，即 $N_{eff} < N_{th}$  时才重采样,，这称为<strong>自适应重采样</strong>。自适应重采样的主要优点是计算量较小，但如何确定恰当的阈值要依据具体的问题而定，目前还没有通用的解决方案。</p>
<h3 id="基本重采样算法"><strong>基本重采样算法</strong></h3><h4 id="多项式重采样">多项式重采样</h4><h1 id="Result"><strong>Result</strong></h1><h1 id="References"><strong>References</strong></h1><ul>
<li>[1]梁军. 粒子滤波算法及其应用. 哈尔滨工业大学博士论文，2009.6</li>
<li>[2]Arulampalam, M. Sanjeev, et al. “<a href="http://cis-linux1.temple.edu/~latecki/Courses/RobotFall08/Papers/ParticleFilterTutorial.pdf" target="_blank" rel="external">A Tutorial on Particle Filters for Online Nonlinear/Non-Gaussian Bayesian Tracking.</a>“ IEEE Transactions on Signal Processing 50.2(2002):174 - 188.</li>
</ul>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/12/11/151211-hexo-mistakes/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          Hexo渲染Markdown文件以及Latex代码出现错误的解决方案
        
      </div>
    </a>
  
  
    <a href="/2015/11/19/151119-OpenCV-Filtering-the-Images/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">OpenCV 学习笔记(6) Filtering the Images</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到：</span>
		<a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
		<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>



<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="151206-particle-filter" data-title="Particle Filter" data-url="site:ocxsBlog.github.io/2015/12/06/151206-particle-filter/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2015 ocxs
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div id="totop" style="position:fixed;bottom:100px;right:50px;cursor: pointer;">
<a title="返回顶部"><img src="/img/scrollup.png"/></a>
</div>
<script src="/js/totop.js"></script>
  </div>
</body>
</html>